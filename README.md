# Image-Synthesis-With-Generative-Adversarial-Networks-GANs-Using-CIFAR-10

CS-GY 6953 / ECE-GY 7123 Deep Learning || Project || Spring 2024 <br />
New York University (NYU) Tandon School of Engineering <br /> <br />

## Abstract

[Abstract should be updated]
<br /> <br />
Please go through the [documents](https://github.com/AvinX12/Image-Synthesis-With-Generative-Adversarial-Networks-GANs-Using-CIFAR-10/tree/main/documents) folder for more info!
<br />

## Model Architecture

GANs consist of two neural networks, a discriminator and a generator which are trained simultaneously through a mini-max game network: <br /> <br />
**• Generator:** Generate photorealistic images indistinguishable from real images. It has convolutional layers, batch normalization, ReLU activation functions, and tanh activation function in the output layer. <br /> <br />
**• Discriminator:** Distinguish between real and fake images generated by the generator. It is similar to generator architecture with leaky ReLU activation, and sigmoid activation in the output layer. <br /> <br />
Please go through the project report in [documents](https://github.com/AvinX12/Image-Synthesis-With-Generative-Adversarial-Networks-GANs-Using-CIFAR-10/tree/main/documents) folder for more info!
<br />

## Dataset

The CIFAR-10 dataset contains 60000 32x32 color images. The dataset has 10 classes, each having 6000 images and these classes are completely mutually exclusive. Training a GAN on CIFAR-10 requires the generator to learn patterns and textures to generate realistic images without demanding a lot of compute resources, making it a suitable benchmark for evaluating the capabilities of GAN architectures for the project.
<br />

## Performance Evaluation

### Fréchet Inception Distance [FID]
Measures the similarity between the distributions of features extracted from real images and generated images. <br />
Lower score indicates that the generated images are more similar to the real images in terms of their visual features. <br />

### Inception Score [IS]
Measures the quality and diversity of generated images based on the output probabilities of an image classification model (Pre-trained ResNet18 Model in our case). <br />
Higher score indicates that the generated images are both diverse and of high quality. <br />

## Results

Generative Adversarial Network (GAN) model have performed well. The negative values of the discriminator loss indicate that the discriminator is able to distinguish between real and fake images effectively. The generator loss values indicate the ability of the generator to produce images that are realistic enough to deceive the discriminator. Loss values stabilize towards the later epochs, indicating that the model has reached a stable state. <br />

![Discriminator and Generator Training Loss Plot](https://github.com/AvinX12/Image-Synthesis-With-Generative-Adversarial-Networks-GANs-Using-CIFAR-10/blob/main/plots/D_G_loss_plot.png)

Please check [DLProjectNotebook.ipynb](https://github.com/AvinX12/Image-Synthesis-With-Generative-Adversarial-Networks-GANs-Using-CIFAR-10/blob/main/DLProjectNotebook.ipynb) file to view how we trained this model.

### Fréchet Inception Distance
FID score: **12.056572421708601** <br /> <br />
Low distance between the feature distributions of real and generated images, suggests that the generated images are relatively close to the real images in terms of their visual features. <br />

### Inception Score
IS score: **1.0** <br /> <br />
Generated images are of goo quality and exhibit a high degree of diversity in terms of their content and appearance. <br />

Please check [ModelEvaluation.ipynb](https://github.com/AvinX12/Image-Synthesis-With-Generative-Adversarial-Networks-GANs-Using-CIFAR-10/blob/main/ModelEvaluation.ipynb) file to view how we calculated these scores.

### Conclusion

Based on these evaluation metrics and inspection of generated images, GAN model has performed well, generating good-quality and diverse images that relatively closely resemble the real ones from CIFAR-10 dataset.

![GAN Generated Image](https://github.com/AvinX12/Image-Synthesis-With-Generative-Adversarial-Networks-GANs-Using-CIFAR-10/blob/main/gan_images/100.png)

## References

1. Krizhevsky, A. (2009). Learning multiple layers of features from tiny images. [click here](https://www.cs.toronto.edu/~kriz/cifar.html)
2. Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio. (2014). Generative Adversarial Networks. [click here](https://arxiv.org/abs/1406.2661)
3. T.Karras,T.Aila,S.Laine,andJ.Lehtinen,Progressive Growing of GANs for Improved Quality, Stability, and Variation. 2018. [click here](https://arxiv.org/abs/1710.10196)

## Team Members
1. Durga Avinash Kodavalla | dk4852 <br />
2. Priyangshu Pal | pp2833 <br />
3. Ark Pandey | ap8652 <br />
